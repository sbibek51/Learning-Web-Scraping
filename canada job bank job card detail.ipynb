{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d22bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8dc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {  \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",  \"Accept-Encoding\": \"gzip, deflate, br\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47ee1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date: 2024-03-26\n"
     ]
    }
   ],
   "source": [
    "current_date = datetime.datetime.now().date()\n",
    "print(\"Current Date:\", current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30f8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jobbank.gc.ca/jobsearch/jobposting/40590051?source=searchresults'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d72a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jobbank.gc.ca/jobsearch/jobposting/40590051?source=searchresults\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5d5f7",
   "metadata": {},
   "source": [
    "## Extract raw html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef31cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(url, headers= headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5387f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "428f9fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdd0873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd527b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa5fb14",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract information\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoctitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m date \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m business \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusiness\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# Extract information\n",
    "title = soup.find('span', class_='noctitle').get_text(strip=True)\n",
    "date = soup.find('li', class_='date').get_text(strip=True)\n",
    "business = soup.find('li', class_='business').get_text(strip=True)\n",
    "location = soup.find('li', class_='location').get_text(strip=True).split(':')[-1].strip() if soup.find('li', class_='location') else \"Location information not available\"\n",
    "salary = soup.find('li', class_='salary').get_text(strip=True).split(':')[-1].strip() if soup.find('li', class_='salary') else \"Salary information not available\"\n",
    "job_number = soup.find('li', class_='source').get_text(strip=True).split(':')[-1].strip() if soup.find('li', class_='source') else \"Job number not available\"\n",
    "\n",
    "print(\"Title:\", title)\n",
    "print(\"Date:\", date)\n",
    "print(\"Business:\", business)\n",
    "print(\"Location:\", location)\n",
    "print(\"Salary:\", salary)\n",
    "print(\"Job Number:\", job_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed86621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188828ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36b87041",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jobbank.gc.ca/jobsearch/jobposting/40590051?source=searchresults'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a1a724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jobbank.gc.ca/jobsearch/jobposting/40590051?source=searchresults\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e58e8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(url, headers= headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "534897e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6022800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cce38c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: Toronto,ON (Remote work available)\n",
      "Salary: $90,000to$120,000YEARannually (To be negotiated)/40 hours per week\n",
      "Employment Terms: Permanent employmentFull time\n",
      "Start Date: \n",
      "Benefits: Health benefits, Financial benefits, Long term benefits, Other benefits\n",
      "Vacancies: vacancies1 vacancy\n",
      "Source: Job Bank#2847289\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the BeautifulSoup object named 'soup'\n",
    "\n",
    "# Find all <li> elements within the <ul> with class \"job-posting-brief colcount-lg-2\"\n",
    "job_info_list = soup.find('ul', class_='job-posting-brief colcount-lg-2').find_all('li')\n",
    "\n",
    "# Initialize variables to store extracted information\n",
    "location = \"\"\n",
    "salary = \"\"\n",
    "employment_terms = \"\"\n",
    "start_date = \"\"\n",
    "benefits = \"\"\n",
    "vacancies = \"\"\n",
    "source = \"\"\n",
    "\n",
    "# Loop through each <li> element to extract information\n",
    "for item in job_info_list:\n",
    "    # Extract location\n",
    "    if \"Location\" in item.get_text():\n",
    "        location = item.find('span', class_='city').get_text(strip=True)\n",
    "        remote_work_available = \"Remote work available\" in item.get_text()\n",
    "        if remote_work_available:\n",
    "            location += \" (Remote work available)\"\n",
    "\n",
    "    # Extract salary\n",
    "    elif \"Salary\" in item.get_text():\n",
    "        salary = item.find('span', class_='attribute-value').get_text(strip=True)\n",
    "\n",
    "    # Extract employment terms\n",
    "    elif \"Terms of employment\" in item.get_text():\n",
    "        employment_terms = item.find('span', class_='attribute-value').get_text(strip=True)\n",
    "\n",
    "    # Extract start date\n",
    "    elif \"Start date\" in item.get_text():\n",
    "        start_date = item.find('span').get_text(strip=True)\n",
    "\n",
    "    # Extract benefits\n",
    "    elif \"Benefits\" in item.get_text():\n",
    "        benefits = item.get_text(strip=True).replace(\"Benefits:\", \"\").strip()\n",
    "\n",
    "    # Extract vacancies\n",
    "    elif \"vacancies\" in item.get_text():\n",
    "        vacancies = item.get_text(strip=True)\n",
    "\n",
    "    # Extract source\n",
    "    elif \"Source\" in item.get_text():\n",
    "        source = item.get_text(strip=True).replace(\"Source\", \"\").strip()\n",
    "\n",
    "# Print the extracted information\n",
    "print(\"Location:\", location)\n",
    "print(\"Salary:\", salary)\n",
    "print(\"Employment Terms:\", employment_terms)\n",
    "print(\"Start Date:\", start_date)\n",
    "print(\"Benefits:\", benefits)\n",
    "print(\"Vacancies:\", vacancies)\n",
    "print(\"Source:\", source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b930fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages: ['English']\n",
      "Education Requirements: [\"Bachelor's degree\", 'or equivalent experience', 'Information technology', 'Computer science', 'Computer and information systems security/information assurance', 'Computer technology/computer systems technology']\n",
      "Experience Requirements: ['Experience an asset']\n",
      "Work Settings: ['Information technology (IT) infrastructure']\n",
      "Responsibilities: []\n",
      "Credentials: []\n",
      "Specializations: []\n",
      "Benefits: []\n"
     ]
    }
   ],
   "source": [
    "# Find the div with id \"comparisonchart\"\n",
    "comparison_chart_div = soup.find('div', id='comparisonchart')\n",
    "\n",
    "# Initialize variables to store extracted information\n",
    "languages = []\n",
    "education_requirements = []\n",
    "experience_requirements = []\n",
    "work_settings = []\n",
    "responsibilities = []\n",
    "credentials = []\n",
    "specializations = []\n",
    "benefits = []\n",
    "\n",
    "# Find all h4 and p elements within the comparison chart div\n",
    "for heading in comparison_chart_div.find_all(['h4', 'p']):\n",
    "    # Extract information based on the headings\n",
    "    if heading.name == 'h4':\n",
    "        # Extract languages, education, experience, and other details\n",
    "        if heading.text == 'Languages':\n",
    "            languages.append(heading.find_next('p').text.strip())\n",
    "        elif heading.text == 'Education':\n",
    "            for item in heading.find_next('ul').find_all('li'):\n",
    "                education_requirements.append(item.text.strip())\n",
    "        elif heading.text == 'Experience':\n",
    "            experience_requirements.append(heading.find_next('p').text.strip())\n",
    "        elif heading.text == 'Work setting':\n",
    "            work_settings.append(heading.find_next('ul').text.strip())\n",
    "        elif heading.text == 'Responsibilities':\n",
    "            for task in heading.find_next('ul').find_all('li'):\n",
    "                responsibilities.append(task.text.strip())\n",
    "        elif heading.text == 'Credentials':\n",
    "            for certificate in heading.find_next('ul').find_all('li'):\n",
    "                credentials.append(certificate.text.strip())\n",
    "        elif heading.text == 'Experience and specialization':\n",
    "            for item in heading.find_next('ul').find_all('li'):\n",
    "                specializations.append(item.text.strip())\n",
    "        elif heading.text == 'Benefits':\n",
    "            for category in heading.find_next('ul').find_all('li'):\n",
    "                benefits.append(category.text.strip())\n",
    "                \n",
    "# Print the extracted information\n",
    "print(\"Languages:\", languages)\n",
    "print(\"Education Requirements:\", education_requirements)\n",
    "print(\"Experience Requirements:\", experience_requirements)\n",
    "print(\"Work Settings:\", work_settings)\n",
    "print(\"Responsibilities:\", responsibilities)\n",
    "print(\"Credentials:\", credentials)\n",
    "print(\"Specializations:\", specializations)\n",
    "print(\"Benefits:\", benefits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1aa83d",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5d240",
   "metadata": {},
   "source": [
    "df = pd.read_csv('job_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59288a1",
   "metadata": {},
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5e7a6",
   "metadata": {},
   "source": [
    "dups=df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c026a",
   "metadata": {},
   "source": [
    "dups_count=dups.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2fbed",
   "metadata": {},
   "source": [
    "dups_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5d988",
   "metadata": {},
   "source": [
    "a=155401\n",
    "b=158186\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912e2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
